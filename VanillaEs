import gym
import numpy
# from Gym_Solver import Gym_Solver
from Agent import Agent
import tensorflow as tf
import numpy as np
import copy
import matplotlib.pyplot as plt

def generate_Gussian(length_list,sigma,theta_shape):
    mean_list = [np.zeros(length_list[i]) for i in range(len(length_list))]
    # mean = np.array([0 for i in range(length)])
    covariance_list = [np.eye(length_list[i]) * sigma for i in range(len(length_list))]
    # covariance = np.eye(length) * sigma
    return [np.random.multivariate_normal(mean_list[i],covariance_list[i]).reshape((theta_shape[i])) for i in range(len(length_list))]

def theta_mat_to_vec(theta):
    for i in range(len(theta) - 1):
        try:
            theta_vec = np.concatenate((theta_vec,theta[i + 1].flatten()),axis = None)
        except:
            theta_vec = np.concatenate((theta[i].flatten(),theta[i+1].flatten()),axis = None)
    return theta_vec

def theta_vec_to_mat(theta_vec,theta_shape):
    theta_mat_list = []
    for i in range(len(theta_shape)):
        start = 0
        portion = theta_shape[i][0] * theta_shape[i][1]
        ele = np.reshape(theta_vec[start:portion],theta_shape[i])
        # np.reshape(ele,theta_shape[i])
        theta_mat_list.append(ele)
        start = start + portion

    return theta_mat_list

# parameter initializations
NumPerturbation = 200
envname = 'BipedalWalkerHardcore-v2'
envname = 'CartPole-v1'
episodes = 500
gamma = 0.99
sigma = 1
lr = 1 * 1e-2

env = gym.make(envname)
# env = gym.make('Humanoid-v2')
# print(env.action_space.n)
# actsize = env.action_space.shape[0]
actsize = env.action_space.n
obsize = env.observation_space.low.size

sess = tf.Session()
sess.run(tf.global_variables_initializer())
Agent_ = Agent(obsize,actsize,sess,gamma)
length_list = Agent_.len_theta
theta_shape = Agent_.theta_shape

#initialize theta
mu, sigma = 0, 0.1
theta = [np.random.normal(mu,sigma,item) for item in theta_shape]

average_reward = 0
reward_list = []
epoch_list = []

plt.ion()
plt.show()
for epoch in range(episodes):
    # epsilon_list = generate_Gussian(length_list,sigma,theta_shape)
    for i in range(NumPerturbation):
        render = False

        reward_theta = 0
        epsilon_list = generate_Gussian(length_list,sigma,theta_shape)
        Agent_plus = Agent(obsize,actsize,sess,gamma,epsilon_list,plus = True)
        # Agent_mins = Agent(obsize,actsize,sess,gamma,epsilon_list,plus = False)
        epsilon_list = theta_mat_to_vec(epsilon_list)
        # print(theta_mat_to_vec(epsilon_list))
        if i % NumPerturbation == 0:
            render = True
        reward_theta += Agent_plus._roll_out(env,theta,render) * epsilon_list
        # reward_theta += (Agent_plus._roll_out(env,theta) * epsilon_list - \
        #     Agent_mins._roll_out(env,theta) * epsilon_list)/2
        # average_reward += Agent_plus.reward + Agent_mins.reward
        average_reward += Agent_plus.reward

    # print(reward_theta)
    average_reward = average_reward / NumPerturbation
    reward_list.append(average_reward)
    epoch_list.append(epoch)
    plt.plot(epoch_list,reward_list,'r')
    plt.draw()
    plt.pause(0.3)
   
    theta = theta_mat_to_vec(theta)
    theta = theta + lr * 1/NumPerturbation / sigma * reward_theta
    # print(theta)
    theta = theta_vec_to_mat(theta,theta_shape)
    # print(theta)
    # a = theta_mat_to_vec(theta)
    # print(a)
    # print((theta_vec_to_mat(a,theta_shape)[0].shape))

    # print(theta_vec_to_mat(theta_vec,theta_shape))

# env.close()
